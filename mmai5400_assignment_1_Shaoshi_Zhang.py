# -*- coding: utf-8 -*-
"""MMAI5400 Assignment #1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yjuuj-fTjmx3VaAWOC1D5zNl-Uk2Ltb2
"""

import requests
from bs4 import BeautifulSoup
import csv

resp = requests.get('https://www.trustpilot.com/review/canadiantire.ca')
html_code = resp.text

# save it so that it can be viewed in an editor
with open('resp.html', 'w') as f:
    f.write(resp.text)

soup = BeautifulSoup(html_code, 'html.parser')
print(soup.title)

# Extract the total number of reviews
print(soup.find_all('h2'))

num_reviews=soup.select('h2')[0].text
import re
p = re.compile(R"[0-9]{1,5}")
m = p.search(num_reviews)
total = m.group()
if m:
    print('Total number of review:', total)
else:
    print("No reviews yet")

# Extract the total number of reviews
total_reviews=soup.find('span', class_ = 'headline__review-count')
total_reviews.text

def get_next_page(soup):
    container = soup.find('a', {'rel': 'next'})
    if not container:
      return
    return 'https://www.trustpilot.com' + container['href']

url = 'http://www.trustpilot.com/review/canadiantire.ca'
link=[]
while True:
    page = requests.get(url)
    page_soup = BeautifulSoup(page.text, 'html.parser')
    url = get_next_page(page_soup)
    link.append(url)
    if not url:
        break

URL = link[:-1]
URL.insert(0,'http://www.trustpilot.com/review/canadiantire.ca')

URL

company = ['Canadian Tire' for i in range(int(total))]
review = []
date = []
rating= []

for x in URL: 
  page = requests.get(x)
  page_soup = BeautifulSoup(page.text, 'html.parser')
  for i in page_soup.find_all('div',{'class':'review-content__body'}):
    per_review = i.find('p',{'class':'review-content__text'})
    review.append(str(per_review))
  for i in page_soup.find_all('div',{'class':'review-content-header__dates'}):
    per_date = i.find('script', { 'data-initial-state':'review-dates'})
    per_date = per_date.text
    p = re.compile(R'([0-9]{4}\-[0-9]{2}\-[0-9]{2}T[0-9]{2}\:[0-9]{2}\:[0-9]{2}\+[0-9]{2}\:[0-9]{2})')
    m = p.search(per_date)
    per_date = m.group()
    date.append(str(per_date))
  for i in page_soup.find_all('div',{'class':'star-rating star-rating--medium'}):
    per_rating = str(i.find('img'))
    p = re.compile(R'([0-9]{1})')
    m = p.search(per_rating)
    per_rating = m.group()
    rating.append(str(per_rating))

new_reviews = []
for i in review:
  new_i = str(i).replace('<br/>','')
  new_i = new_i[35:-17]
  new_reviews.append(new_i)
new_reviews

# open a new file as follows:
f = open("CT_reviews.csv", 'w')
# close it with f.close()
# start a csv writer object:
writer = csv.writer(f, delimiter=',')
# write a row, this writes the header
writer.writerow(["CompanyName", "DatePublished","RatingValue","ReviewBody"])

for i in range(len(review)):
  writer.writerow([company[i], date[i],rating[i],new_reviews[i]])


f.close()

# you can extract the text node with link.contents
# and you can get the actual link href with link.get('href')

len(review)

